import { Injectable } from '@nestjs/common';
import { GoogleGenerativeAI, SchemaType } from '@google/generative-ai';
import { AIService } from './ai.service';

export interface RegisterUserFunctionCall {
  name: 'register_user';
  parameters: {
    name: string;
    email?: string;
    phone?: string;
    problem_description: string;
    urgency_level: 'low' | 'medium' | 'high' | 'urgent';
  };
}

export interface UpdateConversationStatusFunctionCall {
  name: 'update_conversation_status';
  parameters: {
    status: 'collecting_data' | 'analyzing_case' | 'connecting_lawyer' | 'resolved';
    lawyer_needed: boolean;
    specialization_required?: string;
    notes?: string;
  };
}

export type FunctionCall = RegisterUserFunctionCall | UpdateConversationStatusFunctionCall;

@Injectable()
export class GeminiService {
  private genAI: GoogleGenerativeAI;

  constructor(private aiService: AIService) {
    this.genAI = new GoogleGenerativeAI(process.env.GOOGLE_API_KEY!);
  }

  getModel() {
    const config = this.aiService.getCurrentConfig();
    return this.genAI.getGenerativeModel({
      model: 'gemini-1.5-flash',
      systemInstruction: config?.systemPrompt || 'Voc√™ √© um assistente √∫til.',
      tools: [
        {
          functionDeclarations: [
            {
              name: 'register_user',
              description: 'Registra um novo usu√°rio no sistema com dados coletados da conversa',
              parameters: {
                type: SchemaType.OBJECT,
                properties: {
                  name: {
                    type: SchemaType.STRING,
                    description: 'Nome completo do usu√°rio'
                  },
                  email: {
                    type: SchemaType.STRING,
                    description: 'Email do usu√°rio (opcional se n√£o fornecido)'
                  },
                  phone: {
                    type: SchemaType.STRING,
                    description: 'Telefone/WhatsApp do usu√°rio (opcional se n√£o fornecido)'
                  },
                  problem_description: {
                    type: SchemaType.STRING,
                    description: 'Descri√ß√£o resumida do problema jur√≠dico relatado'
                  },
                  urgency_level: {
                    type: SchemaType.STRING,
                    format: 'enum',
                    enum: ['low', 'medium', 'high', 'urgent'],
                    description: 'N√≠vel de urg√™ncia do caso baseado na descri√ß√£o'
                  }
                },
                required: ['name', 'problem_description', 'urgency_level']
              }
            },
            {
              name: 'update_conversation_status',
              description: 'Atualiza o status da conversa e determina pr√≥ximos passos',
              parameters: {
                type: SchemaType.OBJECT,
                properties: {
                  status: {
                    type: SchemaType.STRING,
                    format: 'enum',
                    enum: ['collecting_data', 'analyzing_case', 'connecting_lawyer', 'resolved'],
                    description: 'Status atual da conversa'
                  },
                  lawyer_needed: {
                    type: SchemaType.BOOLEAN,
                    description: 'Se √© necess√°rio conectar com um advogado'
                  },
                  specialization_required: {
                    type: SchemaType.STRING,
                    description: 'Especializa√ß√£o jur√≠dica necess√°ria (se lawyer_needed for true)'
                  },
                  notes: {
                    type: SchemaType.STRING,
                    description: 'Notas adicionais sobre a conversa ou decis√£o'
                  }
                },
                required: ['status', 'lawyer_needed']
              }
            }
          ]
        }
      ]
    });
  }

  async generateAIResponse(messages: { text: string; sender: string }[]): Promise<string> {
    const model = this.getModel();
    const config = this.aiService.getCurrentConfig();

    // Preparar hist√≥rico para chat session
    const history = messages.slice(0, -1).map(msg => ({
      role: msg.sender === 'user' ? 'user' : 'model',
      parts: [{ text: msg.text }],
    }));

    // Iniciar chat com hist√≥rico
    const chat = model.startChat({
      history,
      generationConfig: {
        maxOutputTokens: config?.behaviorSettings?.maxTokens || 1000,
        temperature: config?.behaviorSettings?.temperature || 0.7,
      },
    });

    // √öltima mensagem do usu√°rio
    const lastMessage = messages[messages.length - 1];
    const result = await chat.sendMessage(lastMessage.text);

    return result.response.text();
  }

  async generateAIResponseWithFunctions(
    messages: { text: string; sender: string }[]
  ): Promise<{ response: string; functionCalls?: FunctionCall[] }> {
    const model = this.getModel();
    const config = this.aiService.getCurrentConfig();

    // Preparar hist√≥rico para chat session
    const history = messages.slice(0, -1).map(msg => ({
      role: msg.sender === 'user' ? 'user' : 'model',
      parts: [{ text: msg.text }],
    }));

    // Iniciar chat com hist√≥rico
    const chat = model.startChat({
      history,
      generationConfig: {
        maxOutputTokens: config?.behaviorSettings?.maxTokens || 1000,
        temperature: config?.behaviorSettings?.temperature || 0.7,
      },
    });

    // √öltima mensagem do usu√°rio
    const lastMessage = messages[messages.length - 1];
    console.log('üîç Enviando para Gemini:', lastMessage.text);
    console.log('üîç System prompt ativo:', config?.systemPrompt?.substring(0, 200) + '...');

    const result = await chat.sendMessage(lastMessage.text);

    const response = result.response;
    const functionCalls: FunctionCall[] = [];

    // Debug: verificar estrutura da resposta
    console.log('üîç Resposta completa do Gemini:', JSON.stringify(response, null, 2));

    // Verificar function calls na resposta
    if (response.functionCalls && Array.isArray(response.functionCalls)) {
      console.log(`üîß Encontradas ${response.functionCalls.length} function calls`);
      for (const call of response.functionCalls) {
        console.log(`üîß Function call: ${call.name}`, call.args);
        if (call.name === 'register_user') {
          functionCalls.push({
            name: 'register_user',
            parameters: call.args as RegisterUserFunctionCall['parameters']
          });
        } else if (call.name === 'update_conversation_status') {
          functionCalls.push({
            name: 'update_conversation_status',
            parameters: call.args as UpdateConversationStatusFunctionCall['parameters']
          });
        }
      }
    } else {
      console.log('‚ÑπÔ∏è Nenhuma function call na resposta');
    }

    return {
      response: response.text(),
      functionCalls: functionCalls.length > 0 ? functionCalls : undefined
    };
  }

  // M√©todo para atualizar o prompt do sistema (para administra√ß√£o)
  updateSystemPrompt(newPrompt: string) {
    // Este m√©todo agora delega para o AIService
    console.log('Use AIService.updateConfig() para atualizar o prompt do sistema');
  }

  // M√©todo para obter o prompt atual
  getSystemPrompt(): string {
    const config = this.aiService.getCurrentConfig();
    return config?.systemPrompt || '';
  }
}